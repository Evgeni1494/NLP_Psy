{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from elasticsearch import Elasticsearch\n",
    "from faker import Faker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "docker run -d \\\n",
    "  --name elastic \\\n",
    "  -p 9200:9200 \\\n",
    "  -e \"discovery.type=single-node\" \\\n",
    "  -v /home/apprenant/Documents/DEV_IA/NLP/NLP_Psy/Data:/usr/share/elasticsearch/data \\\n",
    "  docker.elastic.co/elasticsearch/elasticsearch:7.17.10\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temps 2:  Stocker les données avec Elastic Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en place\n",
    "- Démarrer un container à partir de l’image docker.elastic.co/elasticsearch/elasticsearch:7.17.10\n",
    "- en mode détaché -d\n",
    "- monter le volume /usr/share/elasticsearch/data en local\n",
    "- utiliser le mapping de port -p 9200:9200\n",
    "- utiliser la variable -e \"discovery.type=single-node\"\n",
    "- le nom du container sera --name elastic\n",
    "\n",
    "- Visualiser les logs du container \n",
    "- appeler la route racine “/”\n",
    "\n",
    "\n",
    "docker run -d --name elastic -p 9200:9200 -e \"discovery.type=single-node\" -v NLP_Psy/Data docker.elastic.co/elasticsearch/elasticsearch:7.17.10\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "docker run -d --name elastic \n",
    "-p 9200:9200 \n",
    "-e \"discovery.type=single-node\" \n",
    "-v /home/apprenant/Documents/DEV_IA/NLP/NLP_Psy:/usr/share/elasticsearch/data docker.elastic.co/elasticsearch/elasticsearch:7.17.10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "docker logs elastic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "curl -X GET http://localhost:9200/\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapper et importer les données\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poster le mapping d’un index nommé “notes”, contenant :\n",
    "\n",
    "- champ “patient_lastname” qui est un term\n",
    "- champ “patient_firstname” qui est un term\n",
    "- champ “text”, texte analysé en standard\n",
    "- champ “date”, qui est une date\n",
    "- champ “patient_left”, qui est un booléen\n",
    "- champ “emotion”, qui est un term\n",
    "- champ ‘confidence” qui est un float\n",
    "\n",
    "Alimenter l’index “notes” à l’aide du jeu de données et de la librairie Faker. \n",
    "\n",
    "Bonus: Mettez en place un pipeline utilisant le modèle TF-IDF que vous avez développé avec scikit-learn pour remplir l- champs “emotion” et “confidence”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(hosts=[\"http://localhost:9200\"])\n",
    "es.transport.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13195/3707423313.py:21: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use individual parameters.\n",
      "  es.indices.create(index=index_name, body=mapping)\n",
      "/tmp/ipykernel_13195/3707423313.py:21: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  es.indices.create(index=index_name, body=mapping)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Connexion à Elasticsearch\n",
    "es = Elasticsearch(hosts=[\"http://localhost:9200\"])\n",
    "\n",
    "# Mapping de l'index \"notes\"\n",
    "mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"patient_lastname\": {\"type\": \"keyword\"},\n",
    "            \"patient_firstname\": {\"type\": \"keyword\"},\n",
    "            \"text\": {\"type\": \"text\", \"analyzer\": \"standard\"},\n",
    "            \"date\": {\"type\": \"date\"},\n",
    "            \"patient_left\": {\"type\": \"boolean\"},\n",
    "            \"emotion\": {\"type\": \"keyword\"},\n",
    "            \"confidence\": {\"type\": \"float\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Création de l'index avec le mapping\n",
    "index_name = \"notes\"\n",
    "es.indices.create(index=index_name, body=mapping)\n",
    "es.transport.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13195/2487134383.py:16: DeprecationWarning: The 'body' parameter is deprecated and will be removed in a future version. Instead use the 'document' parameter. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  es.index(index=index_name, body=doc)\n",
      "/tmp/ipykernel_13195/2487134383.py:16: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.17/security-minimal-setup.html to enable security.\n",
      "  es.index(index=index_name, body=doc)\n"
     ]
    },
    {
     "ename": "ApiError",
     "evalue": "ApiError(429, 'cluster_block_exception', 'index [notes2] blocked by: [TOO_MANY_REQUESTS/12/disk usage exceeded flood-stage watermark, index has read-only-allow-delete block];')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mApiError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m      7\u001b[0m     doc \u001b[39m=\u001b[39m {\n\u001b[1;32m      8\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpatient_lastname\u001b[39m\u001b[39m\"\u001b[39m: fake\u001b[39m.\u001b[39mlast_name(),\n\u001b[1;32m      9\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpatient_firstname\u001b[39m\u001b[39m\"\u001b[39m: fake\u001b[39m.\u001b[39mfirst_name(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mconfidence\u001b[39m\u001b[39m\"\u001b[39m: row[\u001b[39m'\u001b[39m\u001b[39mConfidence\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     15\u001b[0m     }\n\u001b[0;32m---> 16\u001b[0m     es\u001b[39m.\u001b[39;49mindex(index\u001b[39m=\u001b[39;49mindex_name, body\u001b[39m=\u001b[39;49mdoc)\n\u001b[1;32m     17\u001b[0m es\u001b[39m.\u001b[39mtransport\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Documents/DEV_IA/NLP/NLP_Psy/nlp-env/lib/python3.10/site-packages/elasticsearch/_sync/client/utils.py:414\u001b[0m, in \u001b[0;36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 414\u001b[0m \u001b[39mreturn\u001b[39;00m api(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/DEV_IA/NLP/NLP_Psy/nlp-env/lib/python3.10/site-packages/elasticsearch/_sync/client/__init__.py:2318\u001b[0m, in \u001b[0;36mElasticsearch.index\u001b[0;34m(self, index, document, id, error_trace, filter_path, human, if_primary_term, if_seq_no, op_type, pipeline, pretty, refresh, require_alias, routing, timeout, version, version_type, wait_for_active_shards)\u001b[0m\n\u001b[1;32m   2316\u001b[0m __body \u001b[39m=\u001b[39m document\n\u001b[1;32m   2317\u001b[0m __headers \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39maccept\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mapplication/json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent-type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mapplication/json\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m-> 2318\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mperform_request(  \u001b[39m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m   2319\u001b[0m     __method, __path, params\u001b[39m=\u001b[39;49m__query, headers\u001b[39m=\u001b[39;49m__headers, body\u001b[39m=\u001b[39;49m__body\n\u001b[1;32m   2320\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/DEV_IA/NLP/NLP_Psy/nlp-env/lib/python3.10/site-packages/elasticsearch/_sync/client/_base.py:320\u001b[0m, in \u001b[0;36mBaseClient.perform_request\u001b[0;34m(self, method, path, params, headers, body)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mKeyError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[1;32m    318\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m     \u001b[39mraise\u001b[39;00m HTTP_EXCEPTIONS\u001b[39m.\u001b[39mget(meta\u001b[39m.\u001b[39mstatus, ApiError)(\n\u001b[1;32m    321\u001b[0m         message\u001b[39m=\u001b[39mmessage, meta\u001b[39m=\u001b[39mmeta, body\u001b[39m=\u001b[39mresp_body\n\u001b[1;32m    322\u001b[0m     )\n\u001b[1;32m    324\u001b[0m \u001b[39m# 'X-Elastic-Product: Elasticsearch' should be on every 2XX response.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verified_elasticsearch:\n\u001b[1;32m    326\u001b[0m     \u001b[39m# If the header is set we mark the server as verified.\u001b[39;00m\n",
      "\u001b[0;31mApiError\u001b[0m: ApiError(429, 'cluster_block_exception', 'index [notes2] blocked by: [TOO_MANY_REQUESTS/12/disk usage exceeded flood-stage watermark, index has read-only-allow-delete block];')"
     ]
    }
   ],
   "source": [
    "index_name = \"notes\"\n",
    "df = pd.read_csv(\"Predicted_Data.csv\")\n",
    "fake = Faker()\n",
    "es = Elasticsearch(hosts=[\"http://localhost:9200\"])\n",
    "# Alimentation de l'index \"notes\"\n",
    "for index, row in df.iterrows():\n",
    "    doc = {\n",
    "        \"patient_lastname\": fake.last_name(),\n",
    "        \"patient_firstname\": fake.first_name(),\n",
    "        \"text\": row[\"Text\"],\n",
    "        \"emotion\": row[\"Emotion\"],\n",
    "        \"date\": fake.date(),\n",
    "        \"patient_left\": fake.boolean(),\n",
    "        \"confidence\": row['Confidence']\n",
    "    }\n",
    "    es.index(index=index_name, body=doc)\n",
    "es.transport.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad8af40f3bdd8cde4ab93fab1122f739a205e2e7869cfe0b4c6dd55936b6db87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
